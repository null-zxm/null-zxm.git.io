#### 布隆算法

* 问题

  网络爬虫扒下来的URL去重

* 方法一：使用HashSet

  代码简单，但是消耗内存较大

* 方法二：使用Bitmap

  获取每一个URL的HashCode，更具HashCode的值插入到Bitmap 中去，如果插入的位置已经是1，说明URL重复了就不要了，

  * 问题：字符串的HashCode是会有重复的，不同URL的HashCode可能会相同。

  * 解决方案

    使用多次哈希多次哈希，依次比较

    ##### 布隆算法

    1：创建一个空的Bitmap

    2：把第一个URL按照3🀄种Hash算法，分别生成3个不同的Hash值	假设为5	17	9

    3:  分别判断Bitmap中的5	17	9 是否都为一如果是，那么就是重复了，如果不全都为1就将其设置为1 

    当然也有误判的情况发生！！ 